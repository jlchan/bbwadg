\pdfoutput=1

%\documentclass[preprint,10pt]{elsarticle}
\documentclass[10pt]{article}
%\documentclass[review]{siamart0216}

\usepackage{fullpage}
\usepackage{hyperref}
%\let\proof\relax
%\let\endproof\relax
\usepackage{amsmath,amssymb,amsfonts,mathrsfs}%,amsthm}
\usepackage[titletoc,toc,title]{appendix}

%\usepackage{lineno}
\usepackage{array} 
\usepackage[utf8]{inputenc}
\usepackage{listings}
\usepackage{mathtools}
\usepackage{pdfpages}
\usepackage[textsize=footnotesize,color=green]{todonotes}
\usepackage{bm}
%\usepackage{tikz}
\usepackage[normalem]{ulem}
\usepackage{hhline}

%% ====================================== alg package
\usepackage{algorithm}
\usepackage[noend]{algpseudocode}
\usepackage{algorithmicx}
\algblock{ParFor}{EndParFor}
% customising the new block
\algnewcommand\algorithmicparfor{\textbf{parfor}}
\algnewcommand\algorithmicpardo{\textbf{do}}
\algnewcommand\algorithmicendparfor{\textbf{end\ parfor}}
\algrenewtext{ParFor}[1]{\algorithmicparfor\ #1\ \algorithmicpardo}
\algrenewtext{EndParFor}{\algorithmicendparfor}
%% ====================================== end alg package

\usepackage{graphicx}
\usepackage{subfig}
\usepackage{color}

%% ====================================== graphics

\usepackage{pgfplots}
\usepackage{pgfplotstable}
\definecolor{markercolor}{RGB}{124.9, 255, 160.65}
\pgfplotsset{width=10cm,compat=1.9}
\pgfplotsset{
tick label style={font=\small},
label style={font=\small},
legend style={font=\small}
}

\usetikzlibrary{calc}

%%% START MACRO FOR ANNOTATION OF TRIANGLE WITH SLOPE %%%.
\newcommand{\logLogSlopeTriangle}[5]
{
    % #1. Relative offset in x direction.
    % #2. Width in x direction, so xA-xB.
    % #3. Relative offset in y direction.
    % #4. Slope d(y)/d(log10(x)).
    % #5. Plot options.

    \pgfplotsextra
    {
        \pgfkeysgetvalue{/pgfplots/xmin}{\xmin}
        \pgfkeysgetvalue{/pgfplots/xmax}{\xmax}
        \pgfkeysgetvalue{/pgfplots/ymin}{\ymin}
        \pgfkeysgetvalue{/pgfplots/ymax}{\ymax}

        % Calculate auxilliary quantities, in relative sense.
        \pgfmathsetmacro{\xArel}{#1}
        \pgfmathsetmacro{\yArel}{#3}
        \pgfmathsetmacro{\xBrel}{#1-#2}
        \pgfmathsetmacro{\yBrel}{\yArel}
        \pgfmathsetmacro{\xCrel}{\xArel}

        \pgfmathsetmacro{\lnxB}{\xmin*(1-(#1-#2))+\xmax*(#1-#2)} % in [xmin,xmax].
        \pgfmathsetmacro{\lnxA}{\xmin*(1-#1)+\xmax*#1} % in [xmin,xmax].
        \pgfmathsetmacro{\lnyA}{\ymin*(1-#3)+\ymax*#3} % in [ymin,ymax].
        \pgfmathsetmacro{\lnyC}{\lnyA+#4*(\lnxA-\lnxB)}
        \pgfmathsetmacro{\yCrel}{\lnyC-\ymin)/(\ymax-\ymin)} % THE IMPROVED EXPRESSION WITHOUT 'DIMENSION TOO LARGE' ERROR.

        % Define coordinates for \draw. MIND THE 'rel axis cs' as opposed to the 'axis cs'.
        \coordinate (A) at (rel axis cs:\xArel,\yArel);
        \coordinate (B) at (rel axis cs:\xBrel,\yBrel);
        \coordinate (C) at (rel axis cs:\xCrel,\yCrel);

        % Draw slope triangle.
        \draw[#5]   (A)-- node[pos=0.5,anchor=north] {1}
                    (B)-- 
                    (C)-- node[pos=0.5,anchor=west] {#4}
                    cycle;
    }
}
%%% END MACRO FOR ANNOTATION OF TRIANGLE WITH SLOPE %%%.

\newcommand{\logLogSlopeTriangleNeg}[5]
{
    % #1. Relative offset in x direction.
    % #2. Width in x direction, so xA-xB.
    % #3. Relative offset in y direction.
    % #4. Slope d(y)/d(log10(x)).
    % #5. Plot options.

    \pgfplotsextra
    {
        \pgfkeysgetvalue{/pgfplots/xmin}{\xmin}
        \pgfkeysgetvalue{/pgfplots/xmax}{\xmax}
        \pgfkeysgetvalue{/pgfplots/ymin}{\ymin}
        \pgfkeysgetvalue{/pgfplots/ymax}{\ymax}

        % Calculate auxilliary quantities, in relative sense.
        \pgfmathsetmacro{\xArel}{#1}
        \pgfmathsetmacro{\yArel}{#3}
        \pgfmathsetmacro{\xBrel}{#1-#2}
        \pgfmathsetmacro{\yBrel}{\yArel}
        \pgfmathsetmacro{\xCrel}{\xArel}

        \pgfmathsetmacro{\lnxB}{\xmin*(1-(#1-#2))+\xmax*(#1-#2)} % in [xmin,xmax].
        \pgfmathsetmacro{\lnxA}{\xmin*(1-#1)+\xmax*#1} % in [xmin,xmax].
        \pgfmathsetmacro{\lnyA}{\ymin*(1-#3)+\ymax*#3} % in [ymin,ymax].
        \pgfmathsetmacro{\lnyC}{\lnyA+#4*(\lnxA-\lnxB)}
        \pgfmathsetmacro{\yCrel}{\lnyC-\ymin)/(\ymax-\ymin)} % THE IMPROVED EXPRESSION WITHOUT 'DIMENSION TOO LARGE' ERROR.

        % Define coordinates for \draw. MIND THE 'rel axis cs' as opposed to the 'axis cs'.
        \coordinate (A) at (rel axis cs:\xArel,\yArel);
        \coordinate (B) at (rel axis cs:\xBrel,\yBrel);
        \coordinate (C) at (rel axis cs:\xCrel,\yCrel);

        % Draw slope triangle.
        \draw[#5]   (A)-- node[pos=.5,anchor=south] {1}
                    (B)-- 
                    (C)-- node[pos=0.5,anchor=west] {#4}
                    cycle;
    }
}
%%% END MACRO FOR ANNOTATION OF TRIANGLE WITH SLOPE %%%.

%%% START MACRO FOR ANNOTATION OF TRIANGLE WITH SLOPE %%%.
\newcommand{\logLogSlopeTriangleFlipNeg}[5]
{
    % #1. Relative offset in x direction.
    % #2. Width in x direction, so xA-xB.
    % #3. Relative offset in y direction.
    % #4. Slope d(y)/d(log10(x)).
    % #5. Plot options.

    \pgfplotsextra
    {
        \pgfkeysgetvalue{/pgfplots/xmin}{\xmin}
        \pgfkeysgetvalue{/pgfplots/xmax}{\xmax}
        \pgfkeysgetvalue{/pgfplots/ymin}{\ymin}
        \pgfkeysgetvalue{/pgfplots/ymax}{\ymax}

        % Calculate auxilliary quantities, in relative sense.
        %\pgfmathsetmacro{\xArel}{#1}
        %\pgfmathsetmacro{\yArel}{#3}
        \pgfmathsetmacro{\xBrel}{#1-#2}
        \pgfmathsetmacro{\yBrel}{#3}
        \pgfmathsetmacro{\xCrel}{#1}

        \pgfmathsetmacro{\lnxB}{\xmin*(1-(#1-#2))+\xmax*(#1-#2)} % in [xmin,xmax].
        \pgfmathsetmacro{\lnxA}{\xmin*(1-#1)+\xmax*#1} % in [xmin,xmax].
        \pgfmathsetmacro{\lnyA}{\ymin*(1-#3)+\ymax*#3} % in [ymin,ymax].
        \pgfmathsetmacro{\lnyC}{\lnyA+#4*(\lnxA-\lnxB)}
        \pgfmathsetmacro{\yCrel}{\lnyC-\ymin)/(\ymax-\ymin)} % THE IMPROVED EXPRESSION WITHOUT 'DIMENSION TOO LARGE' ERROR.

	\pgfmathsetmacro{\xArel}{\xBrel}
        \pgfmathsetmacro{\yArel}{\yCrel}

        % Define coordinates for \draw. MIND THE 'rel axis cs' as opposed to the 'axis cs'.
        \coordinate (A) at (rel axis cs:\xArel,\yArel);
        \coordinate (B) at (rel axis cs:\xBrel,\yBrel);
        \coordinate (C) at (rel axis cs:\xCrel,\yCrel);

        % Draw slope triangle.
        \draw[#5]   (A)-- node[pos=0.5,anchor=east] {#4}
                    (B)-- 
                    (C)-- node[pos=0.5,anchor=north] {1}
                    cycle;
    }
}
%%% END MACRO FOR ANNOTATION OF TRIANGLE WITH SLOPE %%%.


%%% START MACRO FOR ANNOTATION OF TRIANGLE WITH SLOPE %%%.
\newcommand{\logLogSlopeTriangleFlip}[5]
{
    % #1. Relative offset in x direction.
    % #2. Width in x direction, so xA-xB.
    % #3. Relative offset in y direction.
    % #4. Slope d(y)/d(log10(x)).
    % #5. Plot options.

    \pgfplotsextra
    {
        \pgfkeysgetvalue{/pgfplots/xmin}{\xmin}
        \pgfkeysgetvalue{/pgfplots/xmax}{\xmax}
        \pgfkeysgetvalue{/pgfplots/ymin}{\ymin}
        \pgfkeysgetvalue{/pgfplots/ymax}{\ymax}

        % Calculate auxilliary quantities, in relative sense.
        %\pgfmathsetmacro{\xArel}{#1}
        %\pgfmathsetmacro{\yArel}{#3}
        \pgfmathsetmacro{\xBrel}{#1-#2}
        \pgfmathsetmacro{\yBrel}{#3}
        \pgfmathsetmacro{\xCrel}{#1}

        \pgfmathsetmacro{\lnxB}{\xmin*(1-(#1-#2))+\xmax*(#1-#2)} % in [xmin,xmax].
        \pgfmathsetmacro{\lnxA}{\xmin*(1-#1)+\xmax*#1} % in [xmin,xmax].
        \pgfmathsetmacro{\lnyA}{\ymin*(1-#3)+\ymax*#3} % in [ymin,ymax].
        \pgfmathsetmacro{\lnyC}{\lnyA+#4*(\lnxA-\lnxB)}
        \pgfmathsetmacro{\yCrel}{\lnyC-\ymin)/(\ymax-\ymin)} % THE IMPROVED EXPRESSION WITHOUT 'DIMENSION TOO LARGE' ERROR.

	\pgfmathsetmacro{\xArel}{\xBrel}
        \pgfmathsetmacro{\yArel}{\yCrel}

        % Define coordinates for \draw. MIND THE 'rel axis cs' as opposed to the 'axis cs'.
        \coordinate (A) at (rel axis cs:\xArel,\yArel);
        \coordinate (B) at (rel axis cs:\xBrel,\yBrel);
        \coordinate (C) at (rel axis cs:\xCrel,\yCrel);

        % Draw slope triangle.
        \draw[#5]   (A)-- node[pos=0.5,anchor=east] {#4}
                    (B)-- 
                    (C)-- node[pos=0.5,anchor=south] {1}
                    cycle;
    }
}
%%% END MACRO FOR ANNOTATION OF TRIANGLE WITH SLOPE %%%.

%% ====================================== macros

\renewcommand{\topfraction}{0.85}
\renewcommand{\textfraction}{0.1}
\renewcommand{\floatpagefraction}{0.75}

\newcommand{\vect}[1]{\ensuremath\boldsymbol{#1}}
\newcommand{\tensor}[1]{\underline{\bm{#1}}}
\newcommand{\del}{\triangle}
\newcommand{\curl}{\grad \times}
\renewcommand{\div}{\grad \cdot}
\newcommand{\td}[2]{\frac{{\rm d}#1}{{\rm d}{\rm #2}}}
\newcommand{\pd}[2]{\frac{\partial#1}{\partial#2}}
\newcommand{\pdd}[2]{\frac{\partial^2#1}{\partial#2^2}}

\newcommand{\bs}[1]{\boldsymbol{#1}}

\newcommand{\equaldef}{\stackrel{\mathrm{def}}{=}}

\newcommand{\tablab}[1]{\label{tab:#1}}
\newcommand{\tabref}[1]{Table~\ref{tab:#1}}

\newcommand{\theolab}[1]{\label{theo:#1}}
\newcommand{\theoref}[1]{\ref{theo:#1}}
\newcommand{\eqnlab}[1]{\label{eq:#1}}
\newcommand{\eqnref}[1]{\eqref{eq:#1}}
\newcommand{\seclab}[1]{\label{sec:#1}}
\newcommand{\secref}[1]{\ref{sec:#1}}
\newcommand{\lemlab}[1]{\label{lem:#1}}
\newcommand{\lemref}[1]{\ref{lem:#1}}

\newcommand{\mb}[1]{\mathbf{#1}}
\newcommand{\mbb}[1]{\mathbb{#1}}
\newcommand{\mc}[1]{\mathcal{#1}}
\newcommand{\nor}[1]{\left\| #1 \right\|}
\newcommand{\snor}[1]{\left| #1 \right|}
\newcommand{\LRp}[1]{\left( #1 \right)}
\newcommand{\LRs}[1]{\left[ #1 \right]}
\newcommand{\LRa}[1]{\left\langle #1 \right\rangle}
\newcommand{\LRb}[1]{\left| #1 \right|}
\newcommand{\LRc}[1]{\left\{ #1 \right\}}
\newcommand{\LRceil}[1]{\left\lceil #1 \right\rceil}

\newcommand{\Grad} {\ensuremath{\nabla}}
\newcommand{\Div} {\ensuremath{\nabla\cdot}}
\newcommand{\Nel} {\ensuremath{{N^\text{el}}}}
\newcommand{\jump}[1] {\ensuremath{\LRs{\![#1]\!}}}
\newcommand{\avg}[1] {\ensuremath{\LRc{\!\{#1\}\!}}}
\newcommand{\uh}{\widehat{u}}
\newcommand{\Bh}{\widehat{B}}
\newcommand{\fnh}{\widehat{f}_n}
\renewcommand{\L}{L^2\LRp{\Omega}}
\newcommand{\Lk}{L^2\LRp{D^k}}
\newcommand{\Dhat}{\widehat{D}}
\newcommand{\Lhat}{L^2\LRp{\Dhat}}
\newcommand{\pO}{\partial\Omega}
\newcommand{\Gh}{\Gamma_h}
\newcommand{\Gm}{\Gamma_{-}}
\newcommand{\Gp}{\Gamma_{+}}
\newcommand{\Go}{\Gamma_0}
\newcommand{\Oh}{\Omega_h}

%\newtheorem{theorem}{Theorem}[section]
%\newtheorem{lemma}[theorem]{Lemma}
%\newtheorem{proposition}[theorem]{Proposition}
%\newtheorem{corollary}[theorem]{Corollary}

%\newenvironment{definition}[1][Definition]{\begin{trivlist}
%\item[\hskip \labelsep {\bfseries #1}]}{\end{trivlist}}
%\newenvironment{example}[1][Example]{\begin{trivlist}
%\item[\hskip \labelsep {\bfseries #1}]}{\end{trivlist}}

\newcommand{\eval}[2][\right]{\relax
  \ifx#1\right\relax \left.\fi#2#1\rvert}

\def\etal{{\it et al.~}}


\def\arr#1#2#3#4{\left[
\begin{array}{cc}
#1 & #2\\
#3 & #4\\
\end{array}
\right]}
\def\vectwo#1#2{\left[
\begin{array}{c}
#1\\
#2\\
\end{array}
\right]}
\def\vecthree#1#2#3{\left[
\begin{array}{c}
#1\\
#2\\
#3\\
\end{array}
\right]}
\def\vectfour#1#2#3#4{\left[
\begin{array}{c}
#1\\
#2\\
#3\\
#4\\
\end{array}
\right]}

\newcommand{\G} {\Gamma}
\newcommand{\Gin} {\Gamma_{in}}
\newcommand{\Gout} {\Gamma_{out}}

\newcommand{\note}[1]{{\color{blue}#1}}
\newcommand{\remark}[1]{\textbf{\color{red}#1}}

\newcommand{\tri}{{\rm tri}}
\newcommand{\sqr}{{\rm quad}}

\newcommand{\refhex}{\widehat{\mathcal{H}}}
\newcommand{\reftet}{\widehat{\mathcal{T}}}
\newcommand{\refwedg}{\widehat{\mathcal{W}}}

\newcommand{\refpyr}{\widehat{\mathcal{P}}}
\newcommand{\refpyrf}{\widehat{\mathcal{P}}^f}
\newcommand{\refpyrfq}{\widehat{\mathcal{P}}^{\sqr}}
\newcommand{\refpyrft}{\widehat{\mathcal{P}}^{\tri}}


\newcommand{\hex}{{\mathcal{H}}}
\newcommand{\tet}{{\mathcal{T}}}
\newcommand{\wedg}{{\mathcal{W}}}

\newcommand{\pyr}{{\mathcal{P}}}
\newcommand{\pyrf}{{\mathcal{P}}^f}
\newcommand{\pyrfq}{{\mathcal{P}}^{\sqr}}
\newcommand{\pyrft}{{\mathcal{P}}^{\tri}}

\newcommand{\LinfDk}{L^{\infty}\LRp{D^k}}

\newcommand{\diag}[1]{{\rm diag}\LRp{#1}}

\newcommand{\half}{1/2}

\newcolumntype{C}[1]{>{\centering\let\newline\\\arraybackslash\hspace{0pt}}m{#1}}

%% d in integrand
\newcommand*\diff[1]{\mathop{}\!{\mathrm{d}#1}}

\makeatletter
\renewcommand\d[1]{\mspace{6mu}\mathrm{d}#1\@ifnextchar\d{\mspace{-3mu}}{}}
\makeatother

\newcommand{\squareface}{[-1,1]^2}

\date{}
\author{Jesse Chan}
\title{On the penalty parameter in first order DG formulations}

\begin{document}

\maketitle
\tableofcontents

%\begin{abstract}
%
%\end{abstract}

\section{Introduction}

\section{DG numerical  fluxes}

We consider a first order system of hyperbolic equations
\[
\bm{A}_0\pd{\bm{U}}{t} + \sum_{i=1}^d \pd{\bm{F}_i(\bm{U})}{\bm{x}_i} = 0,
\]
which may alternatively be written as
\[
\bm{A}_0\pd{\bm{U}}{t} + \sum_{i=1}^d \pd{\LRp{\bm{A}_{i}U}}{\bm{x}_i}, \qquad \bm{A}_{i} = \pd{\bm{F}_i(\bm{U})}{\bm{U}}
\]
where $\bm{A}_{i}$ are symmetric matrices.  The semi-discrete DG formulation for such systems may be written as 
\[
\sum_{D^k \in \Oh} \LRp{\bm{A}_0\pd{\bm{U}}{t},\bm{V} }_{\Lk} = \sum_{D^k \in \Oh}\LRp{ \LRp{\bm{F}_i(\bm{U}), \bm{V}_{,i}}_{\Lk} - \LRa{\bm{F}_i^*(\bm{U})\bm{n}_i,\bm{V}}_{\partial D^k}}
\]
where $\bm{n}$ is the outward normal on a face $f$ of $D^k$, and $\bm{F^*}$ is a numerical flux depending defined on shared faces between two elements.  

For convergence, $\bm{F^*} = \bm{F^*}(\bm{U})$ must be consistent such that, for exact solutions $\bm{U}$, 
\[
\bm{F^*} = \bm{F}(\bm{U}).
\]
Let $f$ be a shared face between two elements $D^{k,+}$ and $D^{k,-}$, and let $\bm{F}^+, \bm{F}^-$ be evaluations of $\bm{F}(\bm{U})$ restricted to $D^{k,+}$ and $D^{k,-}$, respectively.  Typical DG fluxes are defined as the sum of a consistent averaging of $\bm{F}^+$ and $\bm{F}^-$ and a penalization term
\begin{equation}
\bm{F^*} = \avg{\bm{F}_n(\bm{U})} - \bm{W}\jump{\bm{U}},
\label{eq:flux}
\end{equation}
where $\bm{W}$ is some positive-definite matrix, which is required for energy stability.  

The upwind numerical flux is a well-known flux of the form (\ref{eq:flux}).  For some normal vector $\bm{n}$, let $\jump{\bm{A}_n} = \sum_{i=1}^d \jump{\bm{A}_i\bm{n}_i}$.  By \note{add citation}, $\jump{\bm{A}_n}$ contains real eigenvalues, and admits an eigenvalue decomposition
\[
\jump{\bm{A}_n} = \bm{V}{\bm{\Lambda}}\bm{V}^{-1}, \qquad \bm{\Lambda} = 
\left(\begin{array}{ccc}
\lambda_1 & & \\
& \ddots & \\
& & \lambda_d
\end{array}\right).
\]
For problems with continuous coefficients, the upwind numerical flux can be defined as
\[
\bm{F^*} = \bm{A}^+\bm{U}^- + \bm{A}^- \bm{U}^+,
\]
where the matrices $\bm{A}^+,\bm{A}^-$ are constructed from the positive and negative eigenvalues 
\begin{align*}
\bm{A}^+ &= \frac{1}{2}\bm{V} \LRp{\bm{\Lambda} + \LRb{\bm{\Lambda}}} \bm{V}^{-1}\\
\bm{A}^- &= \frac{1}{2}\bm{V} \LRp{\bm{\Lambda} - \LRb{\bm{\Lambda}}} \bm{V}^{-1},
\end{align*}
and $\LRb{\Lambda}$ is the diagonal matrix whose entries consist of the absolute values of the eigenvalues $\LRb{\lambda_i}$.  This can be rewritten as
\[
\bm{F^*} = \avg{\bm{A}\bm{U}} - \bm{V}\LRb{\bm{\Lambda}}\bm{V}^{-1} \jump{\bm{U}}.  
\]

An alternative to upwind fluxes are penalty fluxes, which penalize appropriately defined jumps of the solution.  One such penalty flux is given as
\[
\bm{F^*} = \avg{\bm{A}\bm{U}} - \bm{A}^T \bm{W} \jump{\bm{A}\bm{U}}.  
\]
where $\bm{W}$ is some positive-definite weighting matrix.  In contrast to Lax-Friedrichs fluxes, the penalty flux enforce a weaker continuity.  

\subsection{Example: acoustic wave equation}

Consider the isotropic acoustic wave equation in pressure-velocity form
\begin{align*}
\pd{p}{t} &= \Div \bm{u}\\
\pd{\bm{u}}{t} &= \Grad p.
\end{align*}
Let $\bm{U}$ denote the group variable $\bm{U} = (p,u,v)$, where $u$ and $v$ are the $x$ and $y$ components of velocity.  Then, in two dimensions, the isotropic wave equation is given as
\[
\pd{\bm{U}}{t} + \pd{\bm{A}_x\bm{U}}{x} + \pd{\bm{A}_y\bm{U}}{y} = 0, \qquad \bm{A}_x = 
\left(\begin{array}{ccc}
0 & 1 & 0\\
1 & 0 & 0\\
0 & 0 & 0
\end{array}
\right), \qquad 
\bm{A}_y = 
\left(\begin{array}{ccc}
0 & 0 & 1\\
0 & 0 & 0\\
1 & 0 & 0
\end{array}
\right).
\]
The normal flux matrix $\bm{A}_n$ is then
\[
\bm{A}_n = 
\left(\begin{array}{ccc}
0 & \bm{n}_x & \bm{n}_y\\
\bm{n}_x & 0 & 0\\
\bm{n}_y & 0 & 0
\end{array}
\right)
\]
implying that the penalty fluxes (with $\bm{W} = \tau\bm{I}$) are 
\[
\avg{\bm{A}_n \bm{U}} - \bm{A}_n^T \jump{\bm{A}_n\bm{U}} = \left(\begin{array}{c}
\avg{\bm{u}_n}\\
\avg{p }\bm{n}_x\\
\avg{p }\bm{n}_y
\end{array}
\right) - 
\tau\left(\begin{array}{c}
\jump{p}\\
\jump{\bm{u_n}}\bm{n}_x\\
\jump{\bm{u_n}}\bm{n}_y
\end{array}
\right)
\]
For $\tau = 1$, these fluxes coincide with the upwind fluxes.  

\section{Dependence of spectra on the penalty parameter}

\note{Reproduce Gershgorin proof here.}
We split the DG approximation space into conforming and non-conforming parts, which induces a block matrix
\[
\bm{K} = \left(\begin{array}{cc}
\bm{A} & \bm{B}\\
-\bm{B}^T & \bm{C} + \tau \bm{S}
\end{array}\right).
\]
We will adapt the proof presented in \cite{Warburton20063205} to show that the spectra of $\bm{K}$ splits into two sets as $\tau\rightarrow \infty$, the first of which approaches the eigenvalues of $\bm{A}$, and the second of which moves left of the imaginary axis at a rate of $O(\tau)$.  

We first consider the spectra of $\bm{C} + \tau\bm{S}$.  By the construction of the DG formulation $\bm{C}$ is skew-symmetric, while $\bm{S}$ is symmetric and negative-definite.  Let $\lambda, \bm{u}$ be an eigenpair of $\bm{C} + \tau{\bm{S}}$ corresponding to the largest $N^D$ eigenvalues. Let $\lambda = \alpha + i\beta$ and $\bm{u} = \bm{v} + i\bm{w}$, where $\alpha,\beta$ and $\bm{v},\bm{w}$ are the real and imaginary parts of $\lambda$ and $\bm{u}$, respectively.  Then, expanding and grouping terms in
\[
(\bm{C}+\tau\bm{S})(\bm{v} + i\bm{w}) = (\alpha + i\beta) (\bm{v} + i\bm{w})
\]
we have that
\begin{align*}
(\bm{C}+\tau\bm{S})\bm{v} &= \alpha\bm{v}-\beta\bm{w}\\
(\bm{C}+\tau\bm{S})\bm{w} &= \beta\bm{v}+\alpha\bm{w}.
\end{align*}
Assuming that $\bm{u}^*\bm{u} = \nor{\bm{v}}^2 + \nor{\bm{w}}^2 = 1$, multiplying both sides by $\bm{v}^T,\bm{w}^T$ and straightforward manipulations %yield
%\begin{align*}
%\bm{v}^T\bm{A}\bm{v} &= \alpha\nor{\bm{v}}^2-\beta\bm{v}^T\bm{w}\\
%\bm{w}^T\bm{A}\bm{w} &= \beta\bm{w}^T{\bm{v}}+\alpha\nor{\bm{w}}^2.  
%\end{align*}
%\begin{align*}
%\bm{v}^T\bm{A}\bm{v} + \bm{w}^T\bm{A}\bm{w} &= \alpha\\
%\bm{v}^T\bm{A}\bm{w} - \bm{w}^T\bm{A}\bm{w} &= \beta.
%\end{align*}
using the skew-symmetry of $\bm{C}$ and symmetry of $\bm{S}$ yields
\begin{align*}
\bm{v}^T\bm{C}\bm{w} - \bm{w}^T\bm{C}\bm{w} &= \beta\\
\tau\LRp{\bm{v}^T\bm{S}\bm{v} + \bm{w}^T\bm{S}\bm{w}} &= \alpha.
\end{align*}
Since $\bm{v}^T\bm{C}\bm{w} - \bm{w}^T\bm{C}\bm{w}= 2\bm{w}^T\bm{C}\bm{v} = \beta$ is independent of $\tau$ and $\bm{v},\bm{w}$ are normalized, $\beta$ remains bounded as $\tau\rightarrow \infty$.  Similarly, since $\bm{S}$ is symmetric, negative-definite, and independent of $\tau$, the quantity
\[
\LRb{\bm{v}^T\bm{S}\bm{v} + \bm{w}^T\bm{S}\bm{w}} = \LRb{\frac{\alpha}{\tau}}
\]
is bounded independently of $\tau$, and we conclude that $\LRb{\alpha} = O(\tau)$.  Thus, as $\tau$ increases, the eigenvalues of $\bm{C} + \tau\bm{S}$ are shifted further and further left of the imaginary axis.  

\subsection{Bifurcation of eigenvalue sets}

Following \cite{Warburton20063205}, let $\bm{U}$ and $\bm{Q}$ be unitary matrices whose columns contain the eigenvectors of $\bm{A}$ and $\bm{C} + \tau \bm{S}$, respectively.  Then, applying a block diagonal similarity transform yields
\[
\left(\begin{array}{cc}
\bm{U}^* & \\
& \bm{Q}^*
\end{array}\right)
\left(\begin{array}{cc}
\bm{A} & \bm{B}\\
-\bm{B}^T & \bm{C} + \tau \bm{S}
\end{array}\right)
\left(\begin{array}{cc}
\bm{U} & \\
& \bm{Q}
\end{array}\right)
 = \left(\begin{array}{cc}
\bm{\Lambda}_C & \bm{U}^T\bm{B}\bm{Q}\\
-\bm{Q}^T\bm{B}^T\bm{U} & \bm{\Lambda}_D
\end{array}\right),
\]
where $\bm{\Lambda}_C,\bm{\Lambda}_D$ are diagonal matrices whose entries consist of eigenvalues of $\bm{A},\bm{C} + \tau\bm{S}$, respectively.  Since $\bm{B}$ is independent of $\tau$, $\nor{\bm{U}^T\bm{B}\bm{Q}}$ can be bounded independently of $\tau$, assuming that $\bm{U}$ and $\bm{Q}$ are normalized.  Gerschgorin's theorem applied to $\bm{\Lambda}_C,\bm{\Lambda}_D$ then implies that the eigenvalues of $\bm{K}$ are contained in two sets of discs with radii independent of $\tau$.  The first set of discs are centered around $\lambda^C_i$ for $i = 1,\ldots,N^C$, while the second set of discs are centered around $\lambda^D_i$ for $i = 1,\ldots,N^D$, where ${\rm Re}(\lambda^D_i) = O(\tau)$. 

Consider now the $N^C$ eigenvalues with the smallest magnitude.  By the Gerschgorin argument, these must remain bounded as $\tau \rightarrow \infty$.  Let $\bm{W} = (\bm{W}_C,\bm{W}_D)$ and $\Lambda_C$ be the matrix of eigenvectors and eigenvalues corresponding to these $N^C$ smallest eigenvalues, such that
\[
\left(\begin{array}{cc}
\bm{A} & \bm{B}\\
-\bm{B}^T & \bm{C} + \tau \bm{S}
\end{array}\right)
\left(\begin{array}{c}
\bm{W}_C
\\
\bm{W}_D
\end{array}\right) = 
\left(\begin{array}{c}
\bm{A}\bm{W}_C + \bm{B}\bm{W}_D\\
-\bm{B}^T\bm{W}_C + \bm{C}\bm{W}_D + \tau \bm{S}\bm{W}_D
\end{array}\right)
= 
\bm{\Lambda}_C
\left(\begin{array}{c}
\bm{W}_C
\\
\bm{W}_D
\end{array}\right) 
\]
This implies 
\[
\tau \nor{\bm{S}\bm{W}_D} = \nor{\bm{\Lambda}_C \bm{W}_D + \bm{B}^T\bm{W}_C  - \bm{C}\bm{W}_D}.
\]
Since $\Lambda_C$ remains bounded as $\tau\rightarrow \infty$, the right hand side is bounded independently of $\tau$ under normalization of $\bm{W}_C,\bm{W}_D$, and we conclude that the non-conforming 
\[
\nor{\bm{S}\bm{W}_D} = O(1/\tau).
\]
As a consequence, as $\tau\rightarrow \infty$, the smallest $N^C$ eigenvalues of $\bm{K}$ converge to the purely imaginary eigenvalues of $\bm{A}$.  These correspond to a discretization using a conforming approximation space.  
 
\section{Numerical experiments}





\bibliographystyle{unsrt}
\bibliography{dgpenalty}


\end{document}


